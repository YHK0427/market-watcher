import os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import SystemMessage, HumanMessage
from tavily import TavilyClient

from dotenv import load_dotenv  # <--- [ì¶”ê°€] 1. ì´ê±¸ ì¶”ê°€í•˜ê³ 
load_dotenv()                   # <--- [ì¶”ê°€] 2. ë°”ë¡œ ì‹¤í–‰í•´ì„œ í‚¤ë¶€í„° ì½ê²Œ í•´ì•¼ í•©ë‹ˆë‹¤!

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import SystemMessage, HumanMessage
from tavily import TavilyClient


llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0) 
tavily = TavilyClient(api_key=os.getenv("TAVILY_API_KEY"))

# ... (ë°‘ì— ìžˆëŠ” search_tavily í•¨ìˆ˜ë¶€í„°ëŠ” ê·¸ëŒ€ë¡œ ë‘ì‹œë©´ ë©ë‹ˆë‹¤)
# 1. ë„êµ¬ ì´ˆê¸°í™”
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0) # ë¬´ë£Œ ëª¨ë¸ ì¤‘ ì„±ëŠ¥ ìµœê°•
tavily = TavilyClient(api_key=os.getenv("TAVILY_API_KEY"))

# 2. ê²€ìƒ‰ í•¨ìˆ˜ (Tavily)
def search_tavily(query, topic):
    print(f"   [{topic}] ê²€ìƒ‰ ì¤‘: {query}...")
    # Tavilyì˜ ê³ ê¸‰ ê²€ìƒ‰ ê¸°ëŠ¥ í™œìš© (ë‹µë³€ í’ˆì§ˆ í–¥ìƒ)
    results = tavily.search(
        query=query, 
        topic="news", 
        days=1,       # ì§€ë‚œ 24ì‹œê°„ ë‰´ìŠ¤ë§Œ
        search_depth="advanced",
        max_results=3 # ìƒìœ„ 3ê°œë§Œ
    )
    # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì œëª©ê³¼ ë‚´ìš©, URLë§Œ ë½‘ê¸°
    context = []
    for r in results['results']:
        context.append(f"- ì œëª©: {r['title']}\n- ë‚´ìš©: {r['content']}\n- ë§í¬: {r['url']}")
    
    return "\n\n".join(context)

# 3. ì—ì´ì „íŠ¸ ë…¸ë“œ ì •ì˜

def tech_agent(state):
    print("ðŸš€ [Tech Agent] ê¸°ìˆ  ë™í–¥ ì¡°ì‚¬ ì‹œìž‘...")
    query = "latest AI technology trends LLM detailed tech crunch"
    search_result = search_tavily(query, "Tech")
    return {"tech_data": search_result}

def biz_agent(state):
    print("ðŸ’¼ [Biz Agent] ë¹„ì¦ˆë‹ˆìŠ¤ ì‚¬ë¡€ ì¡°ì‚¬ ì‹œìž‘...")
    # â˜…í•µì‹¬: ë‹¨ìˆœ ë‰´ìŠ¤ ì œì™¸, ì‹¤ì œ ë„ìž… ì‚¬ë¡€ ìœ„ì£¼ ê²€ìƒ‰
    query = "Generative AI enterprise use cases success stories ROI efficiency"
    search_result = search_tavily(query, "Business")
    return {"biz_data": search_result}

def academic_agent(state):
    print("ðŸŽ“ [Academic Agent] ìµœì‹  ë…¼ë¬¸ ì¡°ì‚¬ ì‹œìž‘...")
    query = "top trending AI research papers arxiv huggingface daily"
    search_result = search_tavily(query, "Academic")
    return {"paper_data": search_result}

def summarizer_node(state):
    print("ðŸ“ [Supervisor] ì •ë³´ ì·¨í•© ë° ìµœì¢… ìš”ì•½ ì¤‘...")
    
    # 3ëª…ì˜ ì—ì´ì „íŠ¸ê°€ ê°€ì ¸ì˜¨ ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨
    tech = state.get("tech_data", "")
    biz = state.get("biz_data", "")
    paper = state.get("paper_data", "")

    # Geminiì—ê²Œ ìµœì¢… ë¦¬í¬íŠ¸ ìž‘ì„±ì„ ìš”ì²­
    prompt = f"""
    ë‹¹ì‹ ì€ 'CLOVA Market Watcher'ì˜ ìˆ˜ì„ ë¶„ì„ê°€ìž…ë‹ˆë‹¤.
    ì•„ëž˜ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë…¸ì…˜ì— ì ìž¬í•  ìˆ˜ ìžˆëŠ” ê¹”ë”í•œ ë¦¬í¬íŠ¸ë¥¼ ìž‘ì„±í•´ì£¼ì„¸ìš”.
    
    [ìˆ˜ì§‘ëœ ì •ë³´]
    1. ê¸°ìˆ  ë™í–¥: {tech}
    2. ë¹„ì¦ˆë‹ˆìŠ¤ ì‚¬ë¡€: {biz}
    3. í•™ìˆ  ì—°êµ¬: {paper}

    [ìž‘ì„± ê·œì¹™]
    - ê° ë¶„ì•¼ë³„ë¡œ ê°€ìž¥ ì¤‘ìš”í•œ ë‰´ìŠ¤ 1ê°œì”©ë§Œ ì„ ì •í•˜ì„¸ìš” (ì´ 3ê°œ).
    - í•œêµ­ì–´ë¡œ ìž‘ì„±í•˜ì„¸ìš”.
    - ë‚´ìš©ì€ '3ì¤„ ìš”ì•½' í˜•íƒœë¡œ í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ì“°ì„¸ìš”.
    - ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ì•„ëž˜ì™€ ê°™ì€ Python List[Dict] í˜•ì‹ì˜ JSON ë¬¸ìžì—´ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. (ë§ˆí¬ë‹¤ìš´ ì—†ì´)
    
    [
      {{
        "category": "ê¸°ìˆ ë™í–¥",
        "title": "ë‰´ìŠ¤ ì œëª©",
        "summary": "3ì¤„ í•µì‹¬ ìš”ì•½ ë‚´ìš©...",
        "link": "ì›ë³¸ ê¸°ì‚¬ ë§í¬",
        "importance": "â˜…â˜…â˜…"
      }},
      ... (ë¹„ì¦ˆë‹ˆìŠ¤, í•™ìˆ  í¬í•¨ ì´ 3ê°œ)
    ]
    """
    
    response = llm.invoke(prompt)
    
    # JSON ë¬¸ìžì—´ë§Œ ê¹”ë”í•˜ê²Œ ì¶”ì¶œ (ì „ì²˜ë¦¬)
    content = response.content.replace("```json", "").replace("```", "").strip()
    return {"final_report": content}